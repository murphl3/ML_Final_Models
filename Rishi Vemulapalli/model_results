Model Evaluation Results
========================

Best Model Name: GaussianNB
GaussianNB Validation Accuracy: 0.52

              precision    recall  f1-score   support

           0       1.00      0.40      0.57      1273
           1       0.30      1.00      0.46      327

    accuracy                           0.52      1600
   macro avg       0.65      0.70      0.51      1600
weighted avg       0.86      0.52      0.55      1600

GaussianNB Test Accuracy: 0.52

              precision    recall  f1-score   support

           0       1.00      0.40      0.58      1607
           1       0.29      1.00      0.45      393

    accuracy                           0.52      2000
   macro avg       0.65      0.70      0.51      2000
weighted avg       0.86      0.52      0.55      2000

==================================================

Best Model Name: KNN
Best Parameters for KNN: {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}

KNN Validation Accuracy: 0.88

              precision    recall  f1-score   support

           0       0.89      0.96      0.92      1273
           1       0.77      0.56      0.65      327

    accuracy                           0.88      1600
   macro avg       0.83      0.76      0.79      1600
weighted avg       0.87      0.88      0.87      1600

KNN Test Accuracy: 0.89

              precision    recall  f1-score   support

           0       0.90      0.97      0.93      1607
           1       0.81      0.58      0.67      393

    accuracy                           0.89      2000
   macro avg       0.86      0.77      0.80      2000
weighted avg       0.89      0.89      0.88      2000

==================================================

Best Model Name: XGBoost
XGBoost Validation Accuracy: 0.94

              precision    recall  f1-score   support

           0       0.94      0.99      0.96      1273
           1       0.93      0.74      0.83      327

    accuracy                           0.94      1600
   macro avg       0.94      0.86      0.89      1600
weighted avg       0.94      0.94      0.93      1600

XGBoost Test Accuracy: 0.94

              precision    recall  f1-score   support

           0       0.94      0.99      0.96      1607
           1       0.93      0.74      0.83      393

    accuracy                           0.94      2000
   macro avg       0.94      0.86      0.89      2000
weighted avg       0.94      0.94      0.94      2000

==================================================

